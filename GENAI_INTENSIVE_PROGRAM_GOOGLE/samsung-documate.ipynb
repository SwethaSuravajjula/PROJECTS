{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11472777,"sourceType":"datasetVersion","datasetId":7190056}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# ðŸ”§Samsung DocuMate- Your AI companion for Samsung docs.\n\n\n\n## ðŸ“Œ Objective\nTransform traditional, static product manuals into an interactive, intelligent support experience. \n\nWith the power of **RAG**, users can simply type a question and instantly get precise answers â€” pulled straight from the official manual, along with visual page previews.\n\n---\n\n## ðŸš€ Why This Is Helpful\n\n- âœ¨ **Smart Support**: Empowers users to solve issues on their own through AI-guided responses.\n- \n- ðŸ” **Fast & Accurate**: Uses semantic retrieval to fetch only the most relevant content.\n- \n- ðŸ–¼ï¸ **Visual Assistance**: Provides page previews of relavant PDF Pages for better understanding.\n- \n- ðŸ“¦ **Model-Agnostic**: Works with any Samsung device â€” just enter the model number!\n\n---\n\nðŸ’¡ Whether you're troubleshooting, exploring features, or looking for quick how-tos, this assistant brings manuals to life â€” turning tech confusion into clarity.\n\n\nLinks\nBlog Link: https://medium.com/@21f1002451/samsung-documate-your-ai-companion-for-samsung-docs-a150b16a1ef1\n\nYoutube Link: https://www.youtube.com/watch?v=kCJkCtCbv4Y\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport json# data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:09.162420Z","iopub.execute_input":"2025-04-20T16:28:09.162695Z","iopub.status.idle":"2025-04-20T16:28:09.170842Z","shell.execute_reply.started":"2025-04-20T16:28:09.162673Z","shell.execute_reply":"2025-04-20T16:28:09.169649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install selenium pymupdf langchain-google-genai gradio faiss-cpu\n!pip install langchain-community  # for PyPDFLoader & FAISS vectorstore\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:09.172417Z","iopub.execute_input":"2025-04-20T16:28:09.173098Z","iopub.status.idle":"2025-04-20T16:28:18.090166Z","shell.execute_reply.started":"2025-04-20T16:28:09.173062Z","shell.execute_reply":"2025-04-20T16:28:18.088963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install beautifulsoup4 lxml\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:18.091382Z","iopub.execute_input":"2025-04-20T16:28:18.091695Z","iopub.status.idle":"2025-04-20T16:28:21.943194Z","shell.execute_reply.started":"2025-04-20T16:28:18.091659Z","shell.execute_reply":"2025-04-20T16:28:21.942188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nimport requests\nimport fitz  # PyMuPDF\nimport gradio as gr\nfrom typing import List, Tuple, Dict,Optional\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms.base import LLM\nfrom pydantic import PrivateAttr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:21.949915Z","iopub.execute_input":"2025-04-20T16:28:21.950590Z","iopub.status.idle":"2025-04-20T16:28:21.960157Z","shell.execute_reply.started":"2025-04-20T16:28:21.950560Z","shell.execute_reply":"2025-04-20T16:28:21.959129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_URL = \"https://www.samsung.com/in/support/user-manuals-and-guide/\"\nDOWNLOAD_DIR = \"downloads\"\nDIAGRAM_DIR = \"diagrams\"\nPREVIEW_DIR = \"previews\"\nfor directory in (DOWNLOAD_DIR, DIAGRAM_DIR, PREVIEW_DIR):\n    os.makedirs(directory, exist_ok=True)\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret = user_secrets.get_secret(\"API_KEY\")\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/kaggle/input/silver-fiber/silver-fiber-401514-75aa42fb5a08.json\"\nos.environ[\"GENAI_API_KEY\"] = secret","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:21.961767Z","iopub.execute_input":"2025-04-20T16:28:21.962140Z","iopub.status.idle":"2025-04-20T16:28:22.057151Z","shell.execute_reply.started":"2025-04-20T16:28:21.962111Z","shell.execute_reply":"2025-04-20T16:28:22.055561Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `GenAILLM(api_key: str, model_name: str = None, temperature: float = None)`\n\n**Purpose:**  \nServes as a LangChain-compatible wrapper for integrating Google Generative AI (Gemini models) into LLM pipelines, enabling seamless prompt execution and response handling.\n\n---\n\n**Why is this needed?**\n\n- **LangChain Integration:**  \n  Allows Google GenAI models to be used as drop-in replacements within LangChainâ€™s toolchains.\n\n- **Custom Model Control:**  \n  Supports dynamic selection of model type and temperature tuning for flexibility across use cases.\n\n- **Cleaner Abstraction:**  \n  Provides a structured and reusable interface to send prompts and retrieve responses using Google's GenAI client.\n\n---\n\n**How does this work?**\n\n1. **Initialization:**\n   - Takes in a Google API key and optional configuration parameters.\n   - Initializes the GenAI client via `genai.Client`.\n\n2. **Prompt Execution:**\n   - Overrides the `_call()` method to submit the prompt to the GenAI model and return the plain text response.\n\n3. **Metadata Exposure:**\n   - Implements `_identifying_params` to return the modelâ€™s configuration for reproducibility.\n   - Specifies `_llm_type` as `\"genai\"` for internal tracking within LangChain.\n\nThis class enables smooth and structured use of Gemini models in any pipeline requiring LLM-backed responses.\n\n","metadata":{}},{"cell_type":"code","source":"# Custom LangChain-compatible wrapper for Google's Generative AI (Gemini models)\nclass GenAILLM(LLM):\n    model_name: str = \"gemini-2.0-flash\"   # Default model to use\n    temperature: float = 0.0               # Default temperature for deterministic output\n    _client: any = PrivateAttr()           # Internal GenAI client (not exposed publicly)\n\n    def __init__(self, api_key: str, model_name: str = None, temperature: float = None):\n        from google import genai\n        super().__init__()  # Initialize base LLM class\n        self._client = genai.Client(api_key=api_key)  # Instantiate GenAI client using the API key\n\n        # Optionally override default model and temperature\n        if model_name:\n            self.model_name = model_name\n        if temperature is not None:\n            self.temperature = temperature\n\n    def _call(self, prompt: str, stop=None) -> str:\n        \"\"\"\n        Core function to send a prompt to the LLM and return the generated response text.\n        \"\"\"\n        response = self._client.models.generate_content(\n            model=self.model_name,\n            contents=prompt,\n        )\n        return response.text\n\n    @property\n    def _identifying_params(self) -> Dict:\n        \"\"\"\n        Provides identifying parameters for LangChain to distinguish LLM configurations.\n        \"\"\"\n        return {\"model_name\": self.model_name, \"temperature\": self.temperature}\n\n    @property\n    def _llm_type(self) -> str:\n        \"\"\"\n        Returns the type label used internally by LangChain.\n        \"\"\"\n        return \"genai\"\n\n# Custom exception to raise when no English manual is available for a given model\nclass NoEnglishManualError(Exception):\n    \"\"\"Raised when no English PDF user manual is available for a model.\"\"\"\n    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.058422Z","iopub.execute_input":"2025-04-20T16:28:22.058782Z","iopub.status.idle":"2025-04-20T16:28:22.072892Z","shell.execute_reply.started":"2025-04-20T16:28:22.058754Z","shell.execute_reply":"2025-04-20T16:28:22.072024Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `setup_parser()` Function\n\n**Purpose:**  \nCreates a structured parser and customized prompt template to ensure consistent and accurate responses from an LLM when answering technical questions based solely on provided manual context.\n\n---\n\n**Why is it needed?**\n\n- **Structured Responses:**  \n  Ensures the LLMâ€™s answers follow a predictable, JSON-like format, making it easier to integrate and use responses programmatically.\n\n- **Clear Instructions for LLM:**  \n  Provides explicit guidelines, emphasizing detailed explanations and avoiding the generation of unsupported content (like diagrams not in the context).\n\n- **Improved Reliability:**  \n  By clearly defining response expectations, the function reduces model hallucinations and enhances the reliability of the generated answers, especially useful in precise applications like technical manual queries.\n\n","metadata":{}},{"cell_type":"code","source":"def setup_parser() -> Tuple[StructuredOutputParser, PromptTemplate]:\n    \"\"\"\n    Sets up a structured output parser and a customized prompt template for use in a\n    Retrieval-Augmented Generation (RAG) question-answering pipeline.\n\n    Returns:\n        Tuple[StructuredOutputParser, PromptTemplate]: The parser for formatting outputs\n        and the prompt template that guides the LLM's response behavior.\n    \"\"\"\n\n    # Define the expected schema for the LLM's structured output\n    schemas = [ResponseSchema(name=\"answer\", description=\"The answer to the user's question.\")]\n\n    # Create a structured parser based on the schema\n    parser = StructuredOutputParser.from_response_schemas(schemas)\n\n    # Generate format instructions that tell the LLM how to structure its response\n    format_instructions = parser.get_format_instructions()\n\n    # Define a custom prompt template with embedded format instructions and contextual placeholders\n    prompt_template = PromptTemplate(\n        template=\"\"\"\nYou are a helpful and precise assistant specialized in answering questions based on technical manuals.\n\nUse the following EXACT format for your answer and Do NOT include source:\n{format_instructions}\n\nYour task is to:\n- Provide a clear and **in-depth answer** to the userâ€™s question using only the given manual context.\n- If the answer involves steps or instructions, **explain them in detail** (step-by-step if applicable).\n- If a diagram is *not available* in the context, do NOT invent one.\nManual Context:\n{context}\n\nQuestion: {question}\n\"\"\",\n        input_variables=[\"context\", \"question\"],               # Inputs the prompt expects\n        partial_variables={\"format_instructions\": format_instructions}  # Injects format rules directly\n    )\n\n    # Return both the parser and the prompt for use in the RAG pipeline\n    return parser, prompt_template\n\n# Initialize the output parser and prompt once\noutput_parser, prompt = setup_parser()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.073843Z","iopub.execute_input":"2025-04-20T16:28:22.074090Z","iopub.status.idle":"2025-04-20T16:28:22.099255Z","shell.execute_reply.started":"2025-04-20T16:28:22.074071Z","shell.execute_reply":"2025-04-20T16:28:22.098242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `_extract_json_array(text: str, key: str) â†’ List[dict]`\n\n**Purpose:**  \nEfficiently extract and decode a JSON array associated with a given key from raw webpage content.\n\n---\n\n**Why is it needed?**  \nWhen scraping web data, JSON content often appears embedded directly in the webpage as a plain string. This function ensures accurate extraction of just the JSON array you care about, converting it into a Python-friendly structure for easy data manipulation.\n\n---\n\n**How does it work?**\n\n- **Pattern Matching:**  \n  Uses regular expressions (`re`) to precisely locate the beginning of the JSON array (based on the provided key).\n\n- **Balanced Bracket Parsing:**  \n  Once it finds the array start, the function carefully tracks nested brackets (`[` and `]`) to find exactly where the JSON array ends, ensuring accurate extraction even for deeply nested JSON arrays.\n\n- **JSON Decoding:**  \n  Extracts the substring representing the JSON array and decodes it directly into a Python list of dictionaries using `json.loads()`.\n","metadata":{}},{"cell_type":"code","source":"def _extract_json_array(text: str, key: str) -> List[dict]:\n    \"\"\"\n    Extracts and returns a JSON array corresponding to a specific key from a raw text string.\n    This is useful when JSON content is embedded inside HTML or JavaScript in a webpage.\n\n    Args:\n        text (str): The raw text (typically HTML or JS) containing embedded JSON.\n        key (str): The key whose associated JSON array needs to be extracted.\n\n    Returns:\n        List[dict]: A list of dictionaries representing the parsed JSON array.\n\n    Raises:\n        RuntimeError: If the key is not found or if the array is not properly closed.\n    \"\"\"\n\n    # Build regex pattern to find the start of the JSON array associated with the key\n    pattern = f'\"{key}\"\\\\s*:\\\\s*\\\\['\n    m = re.search(pattern, text)\n\n    # If the key is not found in the text, raise an error\n    if not m:\n        raise RuntimeError(f\"No '{key}' array found in page text.\")\n\n    # Start parsing from the beginning of the array (i.e., just before the first â€œ[â€)\n    start = m.end() - 1\n    depth = 0\n\n    # Iterate over the characters starting from the array's opening bracket\n    for i, ch in enumerate(text[start:], start=start):\n        if ch == '[':\n            depth += 1  # Increment depth for every opening bracket\n        elif ch == ']':\n            depth -= 1  # Decrement depth for every closing bracket\n\n            # When depth returns to zero, the array is completely closed\n            if depth == 0:\n                # Extract the array substring and parse it into Python objects\n                return json.loads(text[start:i+1])\n\n    # If no matching closing bracket is found, raise an error\n    raise RuntimeError(f\"Could not find end of '{key}' array.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.100237Z","iopub.execute_input":"2025-04-20T16:28:22.100531Z","iopub.status.idle":"2025-04-20T16:28:22.124567Z","shell.execute_reply.started":"2025-04-20T16:28:22.100503Z","shell.execute_reply":"2025-04-20T16:28:22.123614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `get_manual_pdf_url(model_name: str)`\n\n**Purpose:**  \nAutomatically retrieves the direct download link and filename of the English PDF user manual for a specific Samsung device model.\n\n---\n\n**Why is this needed?**\n\n- **Automation of manual retrieval:**  \n  Streamlines the process of finding and downloading specific device manuals, eliminating tedious manual searches.\n\n- **Error Handling:**  \n  Gracefully manages situations where the page doesnâ€™t exist, doesnâ€™t contain manual data, or doesn't have an English version available, thus ensuring robust behavior.\n\n- **Efficient filtering:**  \n  Precisely locates the English PDF manuals only, reducing clutter and enhancing the reliability of automated workflows.\n\n---\n\n**How does this work?**\n\n1. **Request Page Content:**  \n   - Constructs the support page URL using the provided `model_name`.\n   - Sends an HTTP request with an appropriate user-agent header to fetch webpage content.\n\n2. **Extract Manuals Data:**  \n   - Parses the webpage text to extract JSON-formatted manual information using `_extract_json_array()`.\n\n3. **Filter and Locate PDF Link:**  \n   - Iterates through each manual entry, checking specifically for English language (`\"EN\"`).\n   - Verifies that the manual description includes `\"user manual\"` and that the file is a `.pdf`.\n\n4. **Returns Link & Filename:**  \n   - If a valid English user manual PDF is found, returns its direct download URL along with the filename.\n   - If no suitable manual is found or errors occur, returns `None`.\n\nThis function simplifies automated manual retrieval for further processing or immediate user access.\n","metadata":{}},{"cell_type":"code","source":"def get_manual_pdf_url(model_name: str) -> Optional[Tuple[str, str]]:\n    \"\"\"\n    Fetches the direct download URL and filename of the English PDF user manual\n    for a given Samsung device model.\n\n    Args:\n        model_name (str): The Samsung model number (e.g., \"SM-A166PLGBINS\").\n\n    Returns:\n        Optional[Tuple[str, str]]: A tuple containing the PDF URL and filename,\n        or None if no English user manual is found.\n    \"\"\"\n\n    # Construct the product support page URL for the given model\n    url = f\"https://www.samsung.com/in/support/model/{model_name}/\"\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n\n    # Attempt to fetch the HTML content of the page\n    try:\n        resp = requests.get(url, headers=headers, timeout=10)\n        resp.raise_for_status()  # Raise an error if response is not 200 OK\n    except requests.RequestException:\n        return None  # Return None if the request fails\n\n    # Try to extract the \"manuals\" JSON array embedded in the page\n    try:\n        manuals = _extract_json_array(resp.text, \"manuals\")\n    except RuntimeError:\n        return None  # Return None if no \"manuals\" key is found or extraction fails\n\n    # Iterate through each manual entry to find a valid English user manual PDF\n    for item in manuals:\n        langs = item.get(\"languageList\", [])\n        \n        # Check if English (\"EN\") is listed in the available languages\n        if not any(lang.get(\"code\") == \"EN\" for lang in langs):\n            continue  # Skip manuals that aren't available in English\n\n        # Extract the download URL and file name\n        href  = item.get(\"downloadUrl\")\n        fname = item.get(\"fileName\", \"\")\n        desc  = item.get(\"englishDescription\", \"\").lower()\n\n        # Ensure it's a valid PDF user manual in English\n        if href and fname.lower().endswith(\".pdf\") and \"user manual\" in desc:\n            return href, fname  # Return the valid PDF URL and file name\n\n    # If no suitable manual is found, return None\n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.125543Z","iopub.execute_input":"2025-04-20T16:28:22.125921Z","iopub.status.idle":"2025-04-20T16:28:22.150516Z","shell.execute_reply.started":"2025-04-20T16:28:22.125857Z","shell.execute_reply":"2025-04-20T16:28:22.149398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `download_manual(href: str, out_path: str)`\n\n**Purpose:**  \nDownloads a PDF manual from a provided URL and saves it directly to the specified local file path.\n\n---\n\n**Why is this needed?**\n\n- **Automated Retrieval:**  \n  Enables automated, seamless downloading of user manuals directly from web resources without manual intervention.\n\n- **Reliability Check:**  \n  Verifies that the downloaded file is indeed a PDF, safeguarding against accidental downloads of incorrect or corrupted files.\n\n- **Flexible Storage:**  \n  Automatically manages directory creation, ensuring the target file location is always accessible, reducing filesystem-related errors.\n\n---\n\n**How does this work?**\n\n1. **Fetch the PDF:**\n   - Sends an HTTP GET request to the provided `href` URL.\n   - Streams the file content efficiently to handle large PDF files.\n\n2. **Validate Content-Type:**\n   - Checks HTTP response headers to confirm the file type contains `\"pdf\"`.\n   - Raises an error immediately if the file is not a PDF.\n\n3. **Save to Local Storage:**\n   - Ensures that the directory specified in `out_path` exists (creating it if necessary).\n   - Writes the downloaded PDF data to the specified file path in manageable chunks (8KB each), optimizing memory usage.\n\n4. **Return the Path:**\n   - Returns the path where the manual has been successfully saved for further use.\n\nThis function is crucial for reliably handling manual downloads within an automated document retrieval and processing workflow.\n","metadata":{}},{"cell_type":"code","source":"def download_manual(href: str, out_path: str) -> str:\n    \"\"\"\n    Downloads a PDF manual from the provided URL and saves it to the specified local path.\n\n    Args:\n        href (str): Direct URL to the PDF manual.\n        out_path (str): Path where the file should be saved locally.\n\n    Returns:\n        str: The full path to the downloaded PDF file.\n\n    Raises:\n        RuntimeError: If the downloaded file is not a PDF.\n    \"\"\"\n\n    # Send a streaming GET request to the provided URL\n    resp = requests.get(href, stream=True, timeout=10)\n    resp.raise_for_status()  # Raise an exception for HTTP errors (e.g., 404, 500)\n\n    # Check the content type to verify that it's a PDF\n    content_type = resp.headers.get(\"Content-Type\", \"\")\n    if \"pdf\" not in content_type.lower():\n        raise RuntimeError(\"Downloaded file is not a PDF.\")\n\n    # Create the output directory if it doesn't exist\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n    # Write the PDF content to a file in chunks (8 KB each) to handle large files efficiently\n    with open(out_path, \"wb\") as f:\n        for chunk in resp.iter_content(1024 * 8):\n            f.write(chunk)\n\n    # Return the path to the saved PDF\n    return out_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.152258Z","iopub.execute_input":"2025-04-20T16:28:22.152567Z","iopub.status.idle":"2025-04-20T16:28:22.176573Z","shell.execute_reply.started":"2025-04-20T16:28:22.152541Z","shell.execute_reply":"2025-04-20T16:28:22.175588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `extract_diagrams(pdf_path: str, output_dir: str = DIAGRAM_DIR)`\n\n**Purpose:**  \nExtracts all diagrams or visual content from a PDF file, saves them as image files (PNG), and returns a structured dictionary mapping page numbers to image paths.\n\n---\n\n**Why is this needed?**\n\n- **Visual Insight Extraction:**  \n  Many user manuals include diagrams that are crucial for understanding hardware layouts or instructions. This function helps extract and display those diagrams separately.\n\n- **Supports RAG or Image-Based Display:**  \n  Enables the downstream use of visuals in RAG systems, UI previews, or image-based retrieval for enhanced user interaction.\n\n- **Fallback Handling:**  \n  Ensures even if no images are embedded, the full page is rendered and savedâ€”so that no visual context is missed.\n\n---\n\n**How does this work?**\n\n1. **Prepare Output Directory:**\n   - Ensures the directory to store extracted images exists.\n\n2. **Open PDF and Iterate Pages:**\n   - Loads the PDF using `PyMuPDF` (`fitz`) and loops through each page.\n\n3. **Extract Images from Page:**\n   - Uses `page.get_images(full=True)` to get all embedded images.\n   - Converts images to RGB if needed and saves them as `pageX_imgY.png`.\n\n4. **Fallback for Image-less Pages:**\n   - If no embedded images are found, renders the **entire page** as a high-res image (`2x` zoom) and saves it as `pageX_full.png`.\n\n5. **Organize Output:**\n   - Stores image paths in a dictionary with page numbers as keys and lists of image file paths as values.\n\n6. **Return Structure:**\n   - Example output:\n     ```python\n     {\n       \"2\": [\"diagrams/page2_img1.png\", \"diagrams/page2_img2.png\"],\n       \"5\": [\"diagrams/page5_full.png\"]\n     }\n     ```\n\nThis function ensures that all visual content from the manual is extracted and available for downstream consumption in your GenAI workflows.\n","metadata":{}},{"cell_type":"code","source":"def extract_diagrams(pdf_path: str, output_dir: str = DIAGRAM_DIR) -> Dict[str, List[str]]:\n    \"\"\"\n    Extracts diagrams or visual content from each page of a PDF manual and saves them as PNG images.\n\n    Args:\n        pdf_path (str): Path to the PDF manual file.\n        output_dir (str): Directory where extracted images will be saved.\n\n    Returns:\n        Dict[str, List[str]]: A dictionary mapping page numbers (as strings) to lists of image file paths.\n    \"\"\"\n\n    # Ensure the output directory exists\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Open the PDF using PyMuPDF (fitz)\n    doc = fitz.open(pdf_path)\n    \n    # Dictionary to hold extracted image paths for each page\n    diagrams: Dict[str, List[str]] = {}\n\n    # Loop through each page in the document\n    for idx, page in enumerate(doc):\n        page_num = idx + 1\n\n        # Attempt to extract embedded images from the page\n        images = page.get_images(full=True)\n        if images:\n            for i, img in enumerate(images, start=1):\n                xref = img[0]  # XREF ID of the image\n                pix = fitz.Pixmap(doc, xref)  # Convert image to a Pixmap\n\n                # Convert to RGB color space if necessary\n                if pix.colorspace.name != 'DeviceRGB':\n                    pix = fitz.Pixmap(fitz.csRGB, pix)\n\n                # Save the image as a PNG file\n                filename = f\"page{page_num}_img{i}.png\"\n                path = os.path.join(output_dir, filename)\n                pix.save(path)\n\n                # Store image path in the dictionary under its page number\n                diagrams.setdefault(str(page_num), []).append(path)\n\n        else:\n            # If no embedded images, render the full page as a high-resolution PNG\n            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for clarity\n            filename = f\"page{page_num}_full.png\"\n            path = os.path.join(output_dir, filename)\n            pix.save(path)\n\n            # Store the rendered image path\n            diagrams.setdefault(str(page_num), []).append(path)\n\n    # Close the PDF file\n    doc.close()\n\n    # Return the dictionary of page-to-image mappings\n    return diagrams\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.177600Z","iopub.execute_input":"2025-04-20T16:28:22.177944Z","iopub.status.idle":"2025-04-20T16:28:22.204891Z","shell.execute_reply.started":"2025-04-20T16:28:22.177914Z","shell.execute_reply":"2025-04-20T16:28:22.203874Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `build_retriever(pdf_path: str)`\n\n**Purpose:**  \nConverts a PDF manual into a searchable vector database retriever, enabling semantic question-answering over its content using embeddings.\n\n---\n\n**Why is this needed?**\n\n- **Foundational for RAG (Retrieval-Augmented Generation):**  \n  This retriever powers the core of the QA system by allowing an LLM to access relevant document chunks instead of hallucinating.\n\n- **Semantic Search Capabilities:**  \n  Enables deep, context-aware retrieval from the manualâ€”beyond keyword matchingâ€”by leveraging Googleâ€™s embedding model.\n\n- **Ensures Data Quality:**  \n  Verifies that the PDF is readable and not corrupted before processing, improving robustness.\n\n---\n\n**How does this work?**\n\n1. **PDF Integrity Check:**\n   - Uses `fitz` to confirm the PDF can be opened. Returns `None` if any issues are found.\n\n2. **Load Document Content:**\n   - Uses `LangChain`â€™s `PyPDFLoader` to extract text from the PDF pages.\n   - If the PDF cannot be parsed (`PdfReadError`), it safely returns `None`.\n\n3. **Split into Chunks:**\n   - Uses `RecursiveCharacterTextSplitter` to break the document into overlapping chunks of ~1000 characters with 200-character overlap.\n   - This helps preserve context across chunk boundaries during retrieval.\n\n4. **Generate Embeddings:**\n   - Applies Googleâ€™s `text-embedding-004` model to convert each chunk into a vector.\n\n5. **Create Vector Store:**\n   - Builds a FAISS index from the embedded chunks for fast similarity-based search.\n\n6. **Return a Retriever:**\n   - Returns a retriever object, which can be queried to fetch the most relevant chunks for any user question.\n\nThis function sets up the backbone for question answering based on the contents of any PDF manual.\n","metadata":{}},{"cell_type":"code","source":"def build_retriever(pdf_path: str):\n    \"\"\"\n    Builds a semantic retriever from a given PDF manual using LangChain components.\n    This allows downstream systems to perform similarity-based retrieval on the document.\n\n    Args:\n        pdf_path (str): Path to the PDF file.\n\n    Returns:\n        Retriever object (or None): Returns a retriever instance if successful, or None if loading fails.\n    \"\"\"\n\n    # Step 1: Verify PDF file integrity using PyMuPDF (fitz)\n    try:\n        import fitz\n        fitz.open(pdf_path).close()  # Attempt to open and immediately close the file\n    except Exception as e:\n        return None  # Return None if the file is invalid or unreadable\n\n    # Step 2: Load document content using LangChain's PDF loader\n    try:\n        loader = PyPDFLoader(pdf_path)\n        docs = loader.load()\n    except PdfReadError as e:\n        return None  # Return None if the PDF cannot be parsed\n\n    # Step 3: Split document into overlapping text chunks\n    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n    chunks = splitter.split_documents(docs)\n\n    # Step 4: Generate vector embeddings for each chunk using Google GenAI\n    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n\n    # Step 5: Create a FAISS vectorstore from the embedded chunks\n    vectorstore = FAISS.from_documents(chunks, embeddings)\n\n    # Step 6: Return a retriever for semantic similarity search\n    return vectorstore.as_retriever()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.205774Z","iopub.execute_input":"2025-04-20T16:28:22.206383Z","iopub.status.idle":"2025-04-20T16:28:22.234357Z","shell.execute_reply.started":"2025-04-20T16:28:22.206352Z","shell.execute_reply":"2025-04-20T16:28:22.233233Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `demo_manual_fetch(model_name: str, download_dir: str = \"./downloads\")`\n\n**Purpose:**  \nFetches and downloads the English PDF user manual for a given Samsung model by orchestrating a series of steps from webpage scraping to file saving.\n\n---\n\n**Why is this needed?**\n\n- **End-to-End Automation:**  \n  This function acts as a single entry point to automate the retrieval of device manuals, combining web scraping, parsing, filtering, and downloading in one go.\n\n- **Rapid Testing & Debugging:**  \n  Originally designed as a demo or utility function to quickly validate that a manual can be found, filtered (English + PDF), and downloaded properly.\n\n- **Ensures Accuracy:**  \n  By previewing the list of all manual entries and only downloading English \"user manual\" PDFs, it guarantees relevance and language appropriateness.\n\n---\n\n**How does this work?**\n\n1. **Construct Page URL:**\n   - Forms the Samsung support page URL using the given `model_name`.\n\n2. **Fetch Webpage & Extract JSON:**\n   - Requests the webpage HTML and tries to extract the `\"manuals\"` array using `_extract_json_array`.\n   - If the array doesn't exist or the page fails to load, the function returns early.\n\n3. **Preview Available Manuals (Commented):**\n   - Iterates through the manuals and prints (commented out) available languages and filenames for inspection.\n\n4. **Select Target Manual:**\n   - Uses `get_manual_pdf_url()` to find the first English PDF titled \"user manual\".\n   - If not found, exits early.\n\n5. **Download Selected Manual:**\n   - Constructs the output path and downloads the manual using `download_manual()`.\n\n6. **Return File Path:**\n   - Returns the final local path of the downloaded PDF if everything succeeds.\n\nThis function is essential during development, testing, or bulk-fetching routines for acquiring device documentation cleanly and efficiently.\n","metadata":{}},{"cell_type":"code","source":"def demo_manual_fetch(model_name: str, download_dir: str = \"./downloads\"):\n    #print(f\"â†’ Testing model: {model_name}\\n\")\n\n    # 1) Raw fetch + JSONâ€array extract\n    page_url = f\"https://www.samsung.com/in/support/model/{model_name}/\"\n    try:\n        resp = requests.get(page_url, headers={\"User-Agent\":\"Mozilla/5.0\"}, timeout=10)\n        resp.raise_for_status()\n    except Exception as e:\n        #print(f\"[Error] Failed to fetch page: {e}\")\n        return\n\n    try:\n        manuals = _extract_json_array(resp.text, \"manuals\")\n        #print(f\"Found {len(manuals)} total entries in the â€œmanualsâ€ array.\")\n    except RuntimeError:\n        #print(\"No â€œmanualsâ€ array at all on the page.\")\n        return\n\n    # Print out each entryâ€™s languages & filename\n    for idx, item in enumerate(manuals, start=1):\n        langs = [lang.get(\"code\") for lang in item.get(\"languageList\",[])]\n        fname = item.get(\"fileName\")\n        #print(f\"  {idx}. {fname:30} langs={langs}\")\n\n    # 2) Pick the first English PDF â€œuser manualâ€\n    result = get_manual_pdf_url(model_name)\n    if result is None:\n        #print(\"\\nâ†’ No English PDF user-manual could be selected.\")\n        return\n    href, fname = result\n    #print(f\"\\nSelected English manual:\\n  URL = {href}\\n  filename = {fname}\")\n\n    # 3) Attempt download\n    out_path = os.path.join(download_dir, fname)\n    ok = download_manual(href, out_path)\n    return out_path\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.235633Z","iopub.execute_input":"2025-04-20T16:28:22.235970Z","iopub.status.idle":"2025-04-20T16:28:22.261192Z","shell.execute_reply.started":"2025-04-20T16:28:22.235947Z","shell.execute_reply":"2025-04-20T16:28:22.259927Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n### `load_manual(model_name: str, download_dir: str = \"./downloads\")`\n\n**Purpose:**  \nBuilds a complete Retrieval-Augmented Generation (RAG) pipeline for a Samsung model by downloading its manual, extracting diagrams, and setting up an LLM-powered QA system.\n\n---\n\n**Why is this needed?**\n\n- **One-Stop Setup for QA:**  \n  Combines all the key componentsâ€”manual fetching, diagram extraction, document indexing, and QA chain creationâ€”into a single callable function.\n\n- **Enables Question Answering:**  \n  Equips the system to answer user queries specifically from the content of the manual, using a combination of semantic retrieval and LLM generation.\n\n- **Foundation for RAG UI or Backend:**  \n  Can be used as the backend logic for apps that allow users to interact with product manuals via natural language.\n\n---\n\n**How does this work?**\n\n1. **Download the Manual:**\n   - Calls `demo_manual_fetch()` to retrieve the English PDF manual.\n   - Raises an error if no valid manual is found.\n\n2. **Extract Diagrams:**\n   - Uses `extract_diagrams()` to process visual content from the manual pages and save them as PNG images.\n\n3. **Build Vector Retriever:**\n   - Constructs a FAISS-based retriever by chunking the manual and embedding the text with Google GenAI embeddings.\n\n4. **Initialize LLM:**\n   - Creates a `GenAILLM` instance using the provided API key (`secret`).\n\n5. **Create RAG Chain:**\n   - Wraps the LLM and retriever in a `RetrievalQA` chain using the \"stuff\" method (simple concatenation of retrieved context).\n   - Injects a custom prompt to guide response formatting and reasoning.\n\n6. **Return Everything:**\n   - Returns a tuple:\n     - `chain`: the QA pipeline,\n     - `pdf_path`: path to the downloaded manual,\n     - `diagrams`: dictionary mapping page numbers to image file paths.\n\nThis function powers the core of the GenAI Samsung manual assistantâ€”turning product documentation into an interactive, visual, and intelligent experience.\n","metadata":{}},{"cell_type":"code","source":"def load_manual(model_name: str, download_dir: str = \"./downloads\"):\n    \"\"\"\n    Loads a Samsung model's user manual, builds the retriever and LLM-based QA chain,\n    and extracts associated diagrams.\n\n    Args:\n        model_name (str): The Samsung device model number (e.g., \"SM-A166PLGBINS\").\n        download_dir (str): Directory to store the downloaded manual.\n\n    Returns:\n        Tuple: (QA chain, PDF path, diagrams dictionary)\n            - chain: A RetrievalQA chain that can answer user queries.\n            - pdf_path: Path to the downloaded user manual.\n            - diagrams: Dictionary mapping page numbers to extracted diagram images.\n    \n    Raises:\n        ValueError: If no English PDF manual is available for the given model.\n    \"\"\"\n\n    # Step 1: Fetch and download the English PDF manual\n    pdf_path = demo_manual_fetch(model_name, download_dir)\n    if not pdf_path:\n        raise ValueError(f\"No English PDF manual available for model '{model_name}'.\")\n\n    # Step 2: Extract diagrams (images or page renderings) from the manual\n    diagrams = extract_diagrams(pdf_path)\n\n    # Step 3: Build a retriever for the manual using chunked embeddings\n    retriever = build_retriever(pdf_path)\n\n    # Step 4: Initialize the custom GenAI LLM with your secret API key\n    llm = GenAILLM(api_key=secret)\n\n    # Step 5: Create a Retrieval-Augmented Generation (RAG) chain\n    chain = RetrievalQA.from_chain_type(\n        llm=llm,\n        chain_type=\"stuff\",  # Concatenates retrieved context before passing to LLM\n        retriever=retriever,\n        chain_type_kwargs={\"prompt\": prompt},  # Use custom prompt template\n        return_source_documents=True  # Include source docs for traceability\n    )\n\n    # Step 6: Return the assembled QA chain, manual PDF path, and extracted diagrams\n    return chain, pdf_path, diagrams\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.262154Z","iopub.execute_input":"2025-04-20T16:28:22.262406Z","iopub.status.idle":"2025-04-20T16:28:22.318366Z","shell.execute_reply.started":"2025-04-20T16:28:22.262386Z","shell.execute_reply":"2025-04-20T16:28:22.317477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `answer_query(question: str, chain, pdf_path: str, diagrams: Dict[str, List[str]])`\n\n**Purpose:**  \nExecutes a natural language query against a product manual using an LLM-powered RAG pipeline, and returns both the structured answer and preview images of the referenced manual pages.\n\n---\n\n**Why is this needed?**\n\n- **Interactive QA with Visuals:**  \n  Enhances LLM responses by pairing text answers with relevant visual previews from the actual manual.\n\n- **Structured & Clean Output:**  \n  Uses the structured parser to extract a clean answer and ensures UI previews reflect only the most relevant content.\n\n- **Context-Aware Retrieval:**  \n  Provides accurate answers grounded in retrieved source documents, boosting both relevance and trustworthiness.\n\n---\n\n**How does this work?**\n\n1. **Clear Old Previews:**\n   - Empties the `PREVIEW_DIR` to prevent overlap with previous queries.\n\n2. **Run QA Chain:**\n   - Sends the userâ€™s question to the LLM retrieval chain.\n   - Parses the structured result using `output_parser`.\n\n3. **Identify Source Pages:**\n   - Collects and sorts page numbers from the retrieved source documents.\n   - These pages are considered contextually relevant for the answer.\n\n4. **Generate Page Previews:**\n   - Opens the PDF and renders each relevant page as a high-resolution image.\n   - Saves each image to `PREVIEW_DIR` and appends its path to `previews`.\n\n5. **Append Extra Info:**\n   - If pages were previewed, appends a note like:  \n     `\"âœ… Preview pages 3â€“4.\"`\n\n6. **Return Final Output:**\n   - Returns a tuple:\n     - `answer`: the parsed and enhanced textual response,\n     - `previews`: a list of image paths for display.\n\nThis function bridges the gap between AI-generated answers and human-readable documentation by merging semantic understanding with visual cues from the manual.\n","metadata":{}},{"cell_type":"code","source":"def answer_query(\n    question: str,\n    chain,\n    pdf_path: str,\n    diagrams: Dict[str, List[str]]\n) -> Tuple[str, List[str]]:\n    \"\"\"\n    Handles user question-answering by querying the RAG pipeline, parsing the response,\n    and generating preview images for the relevant PDF pages.\n\n    Args:\n        question (str): User's natural language query.\n        chain: The RetrievalQA chain used to generate answers.\n        pdf_path (str): Path to the manual PDF file.\n        diagrams (Dict[str, List[str]]): Dictionary mapping page numbers to diagram image paths.\n\n    Returns:\n        Tuple[str, List[str]]: \n            - A well-structured textual answer.\n            - A list of preview image paths from the relevant pages.\n    \"\"\"\n\n    # Step 1: Clear any previous preview images to avoid clutter\n    for fname in os.listdir(PREVIEW_DIR):\n        os.remove(os.path.join(PREVIEW_DIR, fname))\n\n    # Step 2: Execute the RAG chain with the user's question\n    result = chain.invoke({\"query\": question})\n\n    # Step 3: Parse the model output using the structured output parser\n    parsed = output_parser.parse(result.get(\"result\") or result.get(\"output_text\", \"\"))\n\n    # Step 4: Extract page numbers from the source documents used in the response\n    pages = sorted({\n        int(doc.metadata.get(\"page\", 0))\n        for doc in result[\"source_documents\"]\n        if doc.metadata.get(\"page\")\n    })\n\n    # Step 5: Generate image previews for each relevant page\n    previews = []\n    pdf = fitz.open(pdf_path)\n    for page_num in pages:\n        pix = pdf[page_num - 1].get_pixmap(matrix=fitz.Matrix(2, 2))  # High-res rendering\n        preview_path = os.path.join(PREVIEW_DIR, f\"page{page_num}_preview.png\")\n        pix.save(preview_path)\n        previews.append(preview_path)\n    pdf.close()\n\n    # Step 6: Append preview page info to the answer if available\n    extra = f\"\\n\\nâœ… Preview pages {pages[0]}â€“{pages[-1]}.\" if pages else ''\n    answer = f\"{parsed['answer']}{extra}\"\n\n    # Step 7: Return the final answer and the list of preview image paths\n    return answer, previews\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:28:22.319315Z","iopub.execute_input":"2025-04-20T16:28:22.319592Z","iopub.status.idle":"2025-04-20T16:28:22.344516Z","shell.execute_reply.started":"2025-04-20T16:28:22.319572Z","shell.execute_reply":"2025-04-20T16:28:22.343333Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### `main()`\n\nThis function defines and launches the Gradio-based user interface for the Samsung Manual RAG QA system. It allows users to input a Samsung model number, load the corresponding manual, and ask natural language questionsâ€”returning AI-generated answers along with visual previews of the relevant manual pages. This interactive interface bridges user queries with document-driven GenAI responses in a clean and user-friendly way.\n\n#### To test this application here are the sample model numbers:\n\n1. SM-A166PLGBINS\n2. QA55LS03FAULXL\n3. NP754XGK-LS2IN\n4. HMX-F90WP/MEA\n5. NP-N102S-B05IN","metadata":{}},{"cell_type":"code","source":"def main():\n    \"\"\"\n    Launches the Gradio interface for the Samsung Manual RAG QA system.\n    Allows users to load a Samsung manual by model number and ask natural language questions\n    with AI-powered responses and visual page previews.\n    \"\"\"\n\n    # Initialize a Gradio Blocks interface for composing multiple UI components\n    demo = gr.Blocks()\n    with demo:\n        # Title / Header\n        gr.Markdown(\"\"\"## Samsung DocuMate\n                    ### Your AI companion for Samsung docs.\"\"\")\n\n        # Input: Samsung model number (restricted to 15 characters max)\n        model_input = gr.Textbox(\n            label=\"Model Number\",\n            max_lines=1,\n            max_length=20,\n            placeholder=\"Enter Model Number (max 20 chars)\"\n        )\n\n        # Button to trigger manual loading\n        load_btn = gr.Button('Load Manual')\n\n        # Display the loading status (success or error)\n        status = gr.Textbox(label='Status')\n\n        # Non-editable file component to display the downloaded manual\n        pdf_file = gr.File(label='Manual PDF', interactive=False)\n\n        # Input field for natural language questions\n        question_input = gr.Textbox(label='Your Question')\n\n        # Button to trigger answering of the question\n        ask_btn = gr.Button('Ask')\n\n        # Output: Textbox to show the AI-generated answer\n        response_box = gr.Textbox(label='Response')\n\n        # Output: Gallery to show preview images of relevant PDF pages\n        preview_gallery = gr.Gallery(label='Page Preview(s)', type='filepath')\n\n        # State variables to preserve the chain, PDF path, and diagrams across interactions\n        chain_state, path_state, diag_state = gr.State(), gr.State(), gr.State()\n\n        # Logic to handle manual loading when 'Load Manual' button is clicked\n        def on_load(model: str):\n            try:\n                chain, path, diagrams = load_manual(model)  # Build QA system for the model\n                return f'Loaded: {model}', chain, path, diagrams, path\n            except ValueError as e:\n                return str(e), None, None, None, None\n\n        # Link the 'Load Manual' button to the on_load function\n        load_btn.click(\n            fn=on_load,\n            inputs=[model_input],\n            outputs=[status, chain_state, path_state, diag_state, pdf_file]\n        )\n\n        # Link the 'Ask' button to the answer_query function\n        ask_btn.click(\n            fn=answer_query,\n            inputs=[question_input, chain_state, path_state, diag_state],\n            outputs=[response_box, preview_gallery]\n        )\n\n    # Launch the Gradio app\n    demo.launch()\n\n# Entry point for the script\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:42:30.175739Z","iopub.execute_input":"2025-04-20T16:42:30.176215Z","iopub.status.idle":"2025-04-20T16:42:31.648361Z","shell.execute_reply.started":"2025-04-20T16:42:30.176189Z","shell.execute_reply":"2025-04-20T16:42:31.647008Z"}},"outputs":[],"execution_count":null}]}